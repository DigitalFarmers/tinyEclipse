# TinyEclipse — AI Philosophy

## AI Is Not the Product. Control Is.

TinyEclipse does not aim to build the smartest AI.
It aims to build the **most trustworthy AI**.

Raw intelligence without control creates risk.
TinyEclipse exists to eliminate that risk.

---

## Core AI Principles

### 1. AI Must Be Bounded
Every AI agent operates within:
- a defined role
- a defined scope
- a defined dataset
- a defined plan level

No agent is omniscient.
No agent is autonomous.

---

### 2. AI Must Be Explainable
If the AI cannot explain:
- why it answered
- where the information came from
- what its confidence level is

Then the answer is invalid.

---

### 3. AI Must Defer to Humans
When confidence is low:
- AI escalates
- AI creates a ticket
- AI steps aside

Humans remain the final authority.

---

### 4. AI Must Respect Privacy by Design
TinyEclipse:
- never trains on raw personal data
- never stores sensitive information
- only uses anonymized or aggregated statistics

Privacy is enforced at architecture level, not policy level.

---

## The Role of RAG (Retrieval-Augmented Generation)

TinyEclipse does not “know” things.
It **retrieves** them.

Knowledge comes from:
- documents
- structured data
- curated statistics
- approved sources

This ensures:
- freshness
- traceability
- isolation per tenant

---

## Confidence Over Cleverness

Every answer includes:
- an internal confidence score
- a threshold check
- an escalation decision

If the AI is not confident, it does not guess.

Guessing is forbidden.

---

## AI Is a Colleague, Not an Oracle

TinyEclipse agents are designed as:
- assistants
- copilots
- observers

Never as:
- decision makers
- enforcers
- silent operators

AI supports the system.
It does not replace responsibility.

---

## The Rabbit Hole

As TinyEclipse evolves:
- models may change
- capabilities may expand
- interfaces may evolve

But these principles never change.

That is the line we never cross.
